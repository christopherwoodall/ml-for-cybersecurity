{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Cybersecurity\n",
    "## URL Query Binary Classifier\n",
    "\n",
    "In this notebook we will go over creating a very simple URL classifier. In order to classify a URL as `BENIGN` or `MALICIOUS` we will be using LR(Logistic Regression), it requires a single input feature and returns `0` or `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Execute this cell if you are running this notebook in a remote\n",
    "# jupyter environment. This process may take some time.\n",
    "PROJECT_DIR=\"ml-for-cybersecurity\"\n",
    "\n",
    "if [ ! -d \"/${PROJECT_DIR}\" ]; then\n",
    "  git clone \"https://github.com/christopherwoodall/${PROJECT_DIR}\" \"/${PROJECT_DIR}\"\n",
    "  mkdir \"/datasets\"\n",
    "  pip install sklearn matplotlib\n",
    "fi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "project_path   = Path.cwd()\n",
    "datasets_path  = Path(project_path / \"datasets\")\n",
    "benign_path    = Path(datasets_path / \"benign_urls.json\")\n",
    "malicious_path = Path(datasets_path / \"malicious_urls.json\")\n",
    "\n",
    "benign_data    = json.loads(benign_path.read_text(encoding=\"utf8\"))\n",
    "malicious_data = json.loads(malicious_path.read_text(encoding=\"utf8\"))\n",
    "all_data       = benign_data + malicious_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data\n",
    "\n",
    "Now we are going to split the data using `sklearn`'s `train_test_split()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3))\n",
    "\n",
    "x           = vectorizer.fit_transform(all_data)\n",
    "y_malicious = [0 for i in range(0,len(benign_data))]\n",
    "y_benign    = [1 for i in range(0,len(malicious_data))]\n",
    "y           = y_malicious + y_benign\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=16)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "Next let's create a Logistic Regression (aka logit, MaxEnt) classifier; check out the docs [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "clf = LogisticRegression(\n",
    "  class_weight = {1: 2 * len(benign_data) / len(malicious_data), 0: 1.0},\n",
    "  max_iter     = 1000\n",
    ").fit(x_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "Now for the fun part. Below are a list of URLs and their categorization(benign or malicious)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MALICIOUS | q=../etc/passwd\n",
      "MALICIOUS | <img src=xx onerror=confirm(1)>\n",
      "MALICIOUS | example/test/q=<svg onload=confirm('faizan')>\n",
      "MALICIOUS | fsecurify/q=<svg onerror=confirm('fsecurify')>\n",
      "MALICIOUS | contact.php=\"';/><script>alert(1)</script>\n",
      "MALICIOUS | login.php=SELECT password from admin\n",
      "BENIGN | contact.php=foo/bar\n",
      "MALICIOUS | contact/javascript:confirm(1)\n",
      "BENIGN | comment.php=foooooooooooooooobarbaaz\n",
      "MALICIOUS | email.aspx=\"><svg onclick=alert(1)\n",
      "BENIGN | ?google/images\n",
      "BENIGN | facebook.com/post\n",
      "MALICIOUS | example/test/q=<script>alert(1)</script>\n",
      "MALICIOUS | example/test/q=<a href=\"javascript:confirm(1)>\n",
      "BENIGN | example/test.php\n",
      "MALICIOUS | \"><svg onload=confirm(1)>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "test_data = [\n",
    "  \"facebook.com/post\",                                # BENIGN\n",
    "  \"example/test.php\",                                 # BENIGN\n",
    "  \"?google/images\",                                   # BENIGN\n",
    "  \"contact.php=foo/bar\",                              # BENIGN\n",
    "  \"comment.php=foooooooooooooooobarbaaz\",             # BENIGN\n",
    "  \"contact.php=\\\"';/><script>alert(1)</script>\",      # MALICIOUS\n",
    "  \"login.php=SELECT password from admin\",             # MALICIOUS\n",
    "  \"\\\"><svg onload=confirm(1)>\",                       # MALICIOUS\n",
    "  \"q=../etc/passwd\",                                  # MALICIOUS\n",
    "  \"contact/javascript:confirm(1)\",                    # MALICIOUS\n",
    "  \"email.aspx=\\\"><svg onclick=alert(1)\",              # MALICIOUS\n",
    "  \"<img src=xx onerror=confirm(1)>\",                  # MALICIOUS\n",
    "  \"example/test/q=<script>alert(1)</script>\",         # MALICIOUS\n",
    "  \"example/test/q=<svg onload=confirm('faizan')>\",    # MALICIOUS\n",
    "  \"fsecurify/q=<svg onerror=confirm('fsecurify')>\",   # MALICIOUS\n",
    "  \"example/test/q=<a href=\\\"javascript:confirm(1)>\",  # MALICIOUS\n",
    "]\n",
    "random.shuffle(test_data)\n",
    "\n",
    "for url in test_data:\n",
    "  prediction = 'BENIGN' if not clf.predict(vectorizer.transform([url])) else 'MALICIOUS'\n",
    "  print(f\"{prediction} | {url}\")\n",
    "  __import__('time').sleep(0.5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Datasets\n",
    "\n",
    "- [HTTP DATASET CSIC 2010](https://www.isi.csic.es/dataset/)[src](https://www.kaggle.com/datasets/ispangler/csic-2010-web-application-attacks) - Developed at the Information Security Institute of CSIC(Spanish Research National Council), the dataset ccontains thousands of automatically generated web request.\n",
    "- [MACCDC2012](http://www.secrepo.com/) - Dataset containing everything from scanning/recon through explotation as well as some c99 shell traffic. Roughly 22694356 total connections.\n",
    "- [fuzzdb](https://github.com/fuzzdb-project/fuzzdb) - The first and most comprehensive open dictionary of fault injection patterns, predictable resource locations, and regex for matching server responses.\n",
    "\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "This project is a resurrection of Faizan Ahmad's [fWaf](http://web.archive.org/web/20170706222016/http://fsecurify.com/fwaf-machine-learning-driven-web-application-firewall/), please go check out the Github repo [here](https://github.com/faizann24/Fwaf-Machine-Learning-driven-Web-Application-Firewall)!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9337a79df3e5d869f0c5777e0d2b1209a728c6a52c1d44e22a85de3e5a3843fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
